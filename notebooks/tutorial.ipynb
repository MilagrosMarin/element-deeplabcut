{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataJoint Element for Pose Estimation with DeepLabCut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Open-source Data Pipeline for Markerless Pose Estimation in Neurophysiology**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the tutorial for the DataJoint Element for pose estimation analysis. This tutorial aims to provide a comprehensive understanding of the open-source data pipeline by `element-deeplabcut`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pipeline](../images/flowchart.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The package is designed to seamlessly integrate the **model training** and **pose estimation analyses** into a data pipeline and streamline model and video management using DataJoint. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pipeline](../images/pipeline.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the end of this tutorial, you will have a clear grasp of how to set up and integrate the `Element DeepLabCut` into your specific research projects and your lab. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisites\n",
    "\n",
    "Please see the [datajoint tutorials GitHub\n",
    "repository](https://github.com/datajoint/datajoint-tutorials/tree/main) before\n",
    "proceeding.\n",
    "\n",
    "A basic understanding of the following DataJoint concepts will be beneficial to your\n",
    "understanding of this tutorial: \n",
    "1. The `Imported` and `Computed` tables types in `datajoint-python`.\n",
    "2. The functionality of the `.populate()` method. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tutorial Overview**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "+ Setup\n",
    "+ *Activate* the DataJoint pipeline\n",
    "+ *Register* an existing model in the DataJoint pipeline\n",
    "+ *Insert* example data into subject and session tables\n",
    "+ Run the inference task\n",
    "+ Visualize the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Setup**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial examines the behavior of a freely moving mouse in an open-field environment. The goal is to extract pose estimations of the animal's head and tail base from video footage. The resulting x and y coordinates offer valuable insights into the animal's movements, postures, and interactions within the environment. \n",
    "\n",
    "The results of this Element example can be combined with **other modalities** to create a complete customizable data pipeline for your specific lab or study. For instance, you can combine `element-deeplabcut` with `element-calcium-imaging` and `element-array-ephys` to characterize the neural activity along with markless pose estimation during behavior.\n",
    "\n",
    "#### Steps to Run the Element-DeepLabCut\n",
    "\n",
    "The input data for this data pipeline is as follows:\n",
    "\n",
    "- A DeepLabCut (DLC) project folder.\n",
    "\n",
    "- The labeled training data in your DLC project folder.\n",
    "\n",
    "\n",
    "This tutorial includes this DLC project folder with example data and the results as well in `example_data` directory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start this tutorial by importing the packages necessary to run the data pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if os.path.basename(os.getcwd()) == \"notebooks\":\n",
    "    os.chdir(\"..\")\n",
    "assert os.path.basename(os.getcwd()) == \"element-deeplabcut\", (\n",
    "    \"Please move to the \" + \"element directory\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datajoint as dj\n",
    "from pathlib import Path\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the tutorial is run in Codespaces, a private, local database server is created and\n",
    "made available for you. This is where we will insert and store our processed results.\n",
    "Let's connect to the database server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj.conn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Activate the DataJoint pipeline**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial presumes that the `element-deeplabcut` has been pre-configured and instantiated, with the database linked downstream to pre-existing `subject` and `session` tables. Please refer to the\n",
    "[`tutorial_pipeline.py`](./tutorial_pipeline.py) for the source code.\n",
    "\n",
    "Now, we will proceed to import the essential schemas required to construct this data pipeline, with particular attention to the primary components: `train` and `model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tutorial_pipeline import lab, subject, session, train, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can represent the tables in the `model` and `train` schemas as well as some of the upstream dependencies to `session` and `subject` schemas as a diagram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    dj.Diagram(subject)\n",
    "    + dj.Diagram(session)\n",
    "    + dj.Diagram(model)\n",
    "    + dj.Diagram(train)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As evident from the diagram, this data pipeline encompasses several tables associated with different pose estimation components like model, train, and evaluation. A few tables, such as `subject.Subject` or `session.Session`, while important for a complete pipeline, fall outside the scope of the `element-deeplabcut` tutorial, and will therefore, not be explored extensively here. The primary focus of this tutorial will be on the `train` and `model` schemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj.Diagram(train) + dj.Diagram(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Register an existing model in the DataJoint pipeline**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A DeepLabCut project adheres to a specific folder structure, featuring a `config.yaml` file that outlines the model's specifications (located within the `example_data/inbox` directory). \n",
    "\n",
    "To \"register\" this DLC model into the pipeline, the initial step is to define the path to the configuration file. Subsequently, this path should be provided as an input to the function responsible for executing the model registration process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file_rel = (\n",
    "    \"from_top_tracking-DataJoint-2023-10-11/config.yaml\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `insert_new_model` function serves as a convenient function within the `element-deeplacut` for simplifying the model registration process.\n",
    "\n",
    "Upon execution, this function generates a printout featuring vital details such as the `model_name` and `model_description`, along with pertinent information extracted from the configuration file. If all the information is accurate and in order, you can initiate the insertion process by typing 'yes', which will result in the registration of the new model, including its two associated body parts, `head` and `tailbase`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.Model.insert_new_model(\n",
    "    model_name=\"from_top_tracking_model_test\",\n",
    "    dlc_config=config_file_rel,\n",
    "    shuffle=1,\n",
    "    trainingsetindex=0,\n",
    "    model_description=\"Model in example data: from_top_tracking model\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check the `Model` table to confirm that the new model has been registered:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.Model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A significant portion of this data is directly extracted from the `config` file. \n",
    "\n",
    "It's important to highlight that every model added to the `model` table is unique and singular. When introducing a new model, it is mandatory to define a new `model_name`. Replicating an existing model is not permitted; the new model must be entirely distinct. Even if you attempt to employ a different `model_name` for a previously registered model, `DataJoint` will identify this duplication and trigger an error. This model management protocol is crucial for maintining data integrity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Insert example data into subject and session tables**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's delve into the `subject.Subject` and `session.Session` tables and include some example data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject.Subject()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a new entry for a subject in the `Subject` table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subject and Session tables\n",
    "subject.Subject.insert1(\n",
    "    dict(\n",
    "        subject=\"subject6\",\n",
    "        sex=\"F\",\n",
    "        subject_birth_date=\"2020-01-01\",\n",
    "        subject_description=\"hneih_E105\",\n",
    "    ),\n",
    "    skip_duplicates=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create session keys and input them into the `Session` table: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the dictionary named \"session_keys\"\n",
    "session_keys = [\n",
    "    dict(subject=\"subject6\", session_datetime=\"2021-06-02 14:04:22\"),\n",
    "    dict(subject=\"subject6\", session_datetime=\"2021-06-03 14:43:10\"),\n",
    "]\n",
    "\n",
    "# Insert this dictionary in the Session table\n",
    "session.Session.insert(session_keys, skip_duplicates=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm the inserted data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert data into the `VideoRecording` table as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_key = {\n",
    "    \"subject\": \"subject6\",\n",
    "    \"session_datetime\": \"2021-06-02 14:04:22\",\n",
    "    \"recording_id\": \"1\",\n",
    "}\n",
    "model.VideoRecording.insert1(\n",
    "    {**recording_key, \"device\": \"Camera1\"}, skip_duplicates=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert video files into the `VideoRecording.File` table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_files = [\n",
    "    \"./example_data/inbox/from_top_tracking-DataJoint-2023-10-11/videos/train1.mp4\"\n",
    "]\n",
    "\n",
    "model.VideoRecording.File.insert(\n",
    "    {**recording_key, \"file_id\": v_idx, \"file_path\": Path(f)}\n",
    "    for v_idx, f in enumerate(video_files)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, populate the `RecordingInfo` table will extract the metadata from the video sets and storing it in the table. \n",
    "\n",
    "This metadata will serve as a valuable resource for subsequent analyses reliant on video characteristics and as a `lookup` table for accessing this video data whenever necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.RecordingInfo.populate()\n",
    "model.RecordingInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can confirm the accuracy of the inference analysis by cross-referencing it with the number of frames extracted (`nframes`). This count of frames should align with the number of entries for each body part in the pose estimation results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Run the inference task**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `PoseEstimationTask` table serves the purpose of specifying an inference task. Let's delve into the table description:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.PoseEstimationTask.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining and inserting a pose estimation task requires:\n",
    "\n",
    "1. Define a video recording.\n",
    "2. Choose a model.\n",
    "3. Select a task mode (\"load\" or \"trigger\").\n",
    "4. Specify the output directory and any optional parameters.\n",
    "\n",
    "When utilizing the \"trigger\" task mode, DataJoint initiates the inference process, running the DeepLabCut model. The duration of this process can vary, depending on the available hardware. If your hardware lacks GPU support, it's advisable to avoid this mode for this tutorial.\n",
    "\n",
    "For this particular exercise, we have opted for the **\"load\" task** mode since the server lacks the necessary GPU resources for inference. The inference results have already been prepared and can be found in the `example_data\\outbox` directory. \n",
    "\n",
    "If you choose the **\"trigger\" task** mode, DataJoint will handle the entire inference process and produce these sets of files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's establish the keys for the pose estimation task: the recording identifiers, and the chosen model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recording_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_key = {**recording_key, \"model_name\": \"from_top_tracking_model_test\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results can be found at the `pose_estimation_output_dir` location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.PoseEstimationTask.insert1(\n",
    "    {\n",
    "        **task_key,\n",
    "        \"task_mode\": \"load\",\n",
    "        \"pose_estimation_output_dir\": \"from_top_tracking-DataJoint-2023-10-11/videos/device_1_recording_1_model_from_top_tracking_100000_maxiters\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the contents of the `PoseEstimationTask` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.PoseEstimationTask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.PoseEstimation.populate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's examine the contents of the `PoseEstimation` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.PoseEstimation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most crucial table is `PoseEstimation.BodyPartPosition` as it will store the results of the inference: x and y coordinates, and likelihood of the pose estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.PoseEstimation.BodyPartPosition()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the pose estimation process, the task-related entries encompass: `subject`, `session`, `recording_id`, `model name`, and each detected `body_part` (in this case, two entries).\n",
    "\n",
    "Each entry includes `frame_index`, `x_pos` and `y_pos` positions, along with a `likelihood` value (`z_pos` is `None`). \n",
    "\n",
    "These results can be retrieved in the form of a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (\n",
    "    (model.PoseEstimation.BodyPartPosition & task_key)\n",
    "    .fetch(format=\"frame\")\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`frame_index` consists of an array of frame numbers, `x_pos` is a NumPy array of x positions, and `likelihood` is a NumPy array as well.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve the data using the `fetch` method, store it as a Pandas DataFrame, and apply the `explode` function to expand the x and y positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.explode([\"frame_index\", \"x_pos\", \"y_pos\", \"likelihood\"]).reset_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned earlier, a validation step for these results involves verifying the number of entries. Each body part should have 60,000 frames, aligning with the `nframes` value stored in the `RecordingInfo` table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Visualize the results**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, separate the data for the head and tailbase. \n",
    "\n",
    "Following this, create two plots: (1) for the head pose estimation, and (2) for the tail base pose estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "head_data = df[df[\"body_part\"] == \"head\"]\n",
    "tail_data = df[df[\"body_part\"] == \"tailbase\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, figsize=(12, 4))\n",
    "\n",
    "axs[0].set_title(\"x position - Head pose estimation\")\n",
    "axs[0].plot(head_data[\"x_pos\"], label=\"x_pos\")\n",
    "axs[0].set_xlabel(\"time (frames)\")\n",
    "axs[0].set_ylabel(\"pos (pixels)\")\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].set_title(\"y position - Head pose estimation\")\n",
    "axs[1].plot(head_data[\"y_pos\"], label=\"y_pos\")\n",
    "axs[1].set_xlabel(\"time (frames)\")\n",
    "axs[1].set_ylabel(\"pos (pixels)\")\n",
    "axs[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, figsize=(12, 4))\n",
    "axs[0].set_title(\"x position - Tailbase pose estimation\")\n",
    "axs[0].plot(head_data[\"x_pos\"], label=\"x_pos\", color=\"orange\")\n",
    "axs[0].set_xlabel(\"time (frames)\")\n",
    "axs[0].set_ylabel(\"pos (pixels)\")\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].set_title(\"y position - Tailbase pose estimation\")\n",
    "axs[1].plot(head_data[\"y_pos\"], label=\"y_pos\", color=\"orange\")\n",
    "axs[1].set_xlabel(\"time (frames)\")\n",
    "axs[1].set_ylabel(\"pos (pixels)\")\n",
    "axs[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, let's generate a plot that displays the head and tailbase positions on the same graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, figsize=(6, 10))\n",
    "\n",
    "axs[0].set_title(\"Head pose estimation\")\n",
    "axs[0].plot(head_data[\"x_pos\"], head_data[\"y_pos\"], label=\"head\", color=\"blue\")\n",
    "axs[0].set_xlabel(\"x position (pixels)\")\n",
    "axs[0].set_ylabel(\"y position (pixels)\")\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].set_title(\"Tailbase pose estimation\")\n",
    "axs[1].plot(tail_data[\"x_pos\"], tail_data[\"y_pos\"], label=\"tailbase\", color=\"orange\")\n",
    "axs[1].set_xlabel(\"x position (pixels)\")\n",
    "axs[1].set_ylabel(\"y position (pixels)\")\n",
    "axs[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have generated the spatial mapping plot for both body parts, head and tail base."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following this tutorial, we have:\n",
    "+ Covered the essential functionality of `element-deeplabcut`\n",
    "+ Acquired the skills to integrate an existing DeepLabCut model into the pipeline\n",
    "+ Learned how to manually insert data into tables\n",
    "+ Executed and ingested results of the pose estimation analysis with DeepLabCut\n",
    "+ Visualized the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Documentation and DataJoint tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Detailed [documentation on `element-deeplabcut`](https://datajoint.com/docs/elements/element-deeplabcut/0.2/)\n",
    "+  [General `DataJoint-Python` interactive tutorials](https://github.com/datajoint/datajoint-tutorials), covering fundamentals, such as table tiers, query operations, fetch operations, automated computations with the make function, and more.\n",
    "+ [Documentation for `DataJoint-Python`](https://datajoint.com/docs/core/datajoint-python/0.14/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
